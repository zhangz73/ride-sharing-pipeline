{
    "map": {
        "data_dir": "Map/map_1000car5region.tsv"
    },
    "trip_demand": {
        "parameter_source": "given",
        "arrival_type": "poisson",
        "parameter_fname": "TripDemand/trip_demand_1000car5region.tsv",
        "data": null
    },
    "reward": {
        "reward_fname": "Payoff/payoff_1000car5region.tsv"
    },
    "mdp": {
        "time_horizon": 360,
        "connection_patience": 0,
        "pickup_patience": 5,
        "num_battery_levels": 1,
        "use_charging_curve": false,
        "battery_jump": 0.3,
        "charging_rates": [
            2
        ],
        "battery_offset": 0,
        "battery_per_step": 0,
        "normalize_by_tripnums": true,
        "region_battery_car_fname": "RegionBatteryCar/region_battery_car_1000car5region.tsv",
        "region_rate_plug_fname": "RegionRatePlug/region_rate_plug_1000car5region.tsv"
    },
    "solver": {
        "type": "ppo"
    },
    "neural": {
        "value_model_name": "discretized_feedforward",
        "value_hidden_dim_lst": [500, 64, 64],
        "value_activation_lst": ["tanh", "relu", "tanh"],
        "value_batch_norm": false,
        "value_lr": 1e-2,
        "value_epoch": 50,
        "value_batch": 100,
        "value_decay": 0.1,
        "value_scheduler_step": 50,
        "value_solver": "Adam",
        "value_retrain": true,
        "policy_model_name": "discretized_feedforward",
        "policy_hidden_dim_lst": [500, 64, 64],
        "policy_activation_lst": ["tanh", "tanh", "tanh"],
        "policy_batch_norm": false,
        "policy_lr": 5e-5,
        "policy_epoch": 3,
        "policy_batch": 100,
        "policy_decay": 0.1,
        "policy_scheduler_step": 1000,
        "policy_solver": "Adam",
        "policy_retrain": true,
        "descriptor": "PPO",
        "dir": ".",
        "num_days": 1,
        "car_batch": 20,
        "gamma": 1,
        "num_itr": 80,
        "num_episodes": 300,
        "ckpt_freq": 10,
        "benchmarking_policy": "uniform",
        "eps": 0.2,
        "eps_sched": 1,
        "eps_eta": 0.97,
        "policy_syncing_freq": 1,
        "n_cpu": 50,
        "lazy_removal": true,
        "state_reduction": true
    },
    "metric": ["total_payoff"],
    "report": {
        "plot": ["training_loss"],
        "table": [],
        "gamma": 1
    }
}
